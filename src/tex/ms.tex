% Define document class
\documentclass[twocolumn]{aastex631}
\usepackage{showyourwork}
\usepackage{color}

\definecolor{rb4}{HTML}{27408B}
\newcommand{\kw}[1]{{\color{rb4}[KW: #1 ]}}

% Begin!
\begin{document}

% Title
\title{Turbo fast no compromise gravitational wave parameter estimation}

% Author list
\author{@kazewong}

% Abstract with filler text
\begin{abstract}
We do one thing and one thing only, gravitational wave parameters estimation, and we do it in turbo mode.
\end{abstract}

% Main body with filler text
\section{Introduction}
\label{sec:intro}

\section{Gravitational wave parameter estimation}

\subsection{Heterodyned likelihood}

\subsection{Waveform}

\section{FlowMC}

\section{Gradient-based sampler}
\label{sec:gradient}

\section{Normalizing Flow}
\label{sec:flow}

\section{Accelerators}
\label{sec:accelerators}

\section{Discussion}

\kw{Talks about implication}
\begin{enumerate}
    \item Multi-modality in testing GR PE
    \item No pre-training, i.e. more adaptive to glitch and new noise model
    \item As gauruntee to converge as other MCMC method
    \item Access to higher dimensional problem
    \item Much lower computational cost, allow poor institute to just run PE on colab if they want.
\end{enumerate}

\kw{Talk about future development}

There are a number of future developments we are working on.
While IMRPhenomD is a reasonable start, it lacks some qualitative features that other state-of-the-art models have,
such as precession and eccentricity \kw{cite}.
It also has higher mismatch with reference numerical relativity waveforms compared to other waveforms.
Currently, we are working on building differentiable IMRPhenomX and NRSurrogate waveforms.
Going forward, we encourage the waveform development community to leverage autodiff environment such as Jax when constructing new waveform models.
Having a differentiable waveform model is not only beneficial for parameter estimation, but also for other applications such as calibrating waveforms to numerical relativity result, as detailed in \kw{cite}.

The features we have implemented are the barebone version of parameter estimation.
We do not include marginalization schemes such as time, phase and calibration lines marginalization.
Because of the performance of the sampler on accelerators, time and phase marginalization is not necessary,
as the performance of our implementation is not significantly impacted by having two extra dimension.
Other marginalization mode should be considered in the future.

Jax's JIT compilation drastically reduce the computational time to evaluate the likelihood.
However, it comes with a compilation overhead when the likelihood is evaluated for the first time.
We observed the compilation time could depends on the device where the code will be run.
This is expected since Jax leverage Accelerated Linear Algebra (XLA) to take advantage of accelerators,
which means Jax needs to compile the code for the specific device according to its architecture.
On an Nvidia A100 GPU, the compilation overhead could go up to 5 minutes for the waveform we are using.
For the cases we have studied, the time needed to obtain converging results on a A100 is about 2-3 minutes.
This means the compilation overhead is dominating the wall-clock time of the specific PE run we considered.
To utilize our implementation to its full potential, we are looking into ways to reduce the compilation overhead,
or to cache the compilation results to avoid paying the compilation overhead for every events.

\begin{enumerate}
    \item Multi-device scaling?
    \item Other detectors configuration
    \item  Combining with noise inference
    \item Higher dimensional problems need HMC still

\end{enumerate}

\section{Acknowledgements}

\bibliography{bib}

\end{document}
